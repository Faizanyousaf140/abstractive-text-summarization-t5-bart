{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "adac8f745c7c4682941a95ff88b2f961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23bee10ef4af48629ab1cbe6f9b28c9a",
              "IPY_MODEL_09308b26c35a471ab9133066d2632a91",
              "IPY_MODEL_a8f8ef9154b24b6580b70a807410f615"
            ],
            "layout": "IPY_MODEL_2182a4bc7c8d4746b7589d95127356fb"
          }
        },
        "23bee10ef4af48629ab1cbe6f9b28c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25dc60de85cc4df99aaaf2ad06e39363",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e0a6c694c7ba49bc836f9ed04da242b8",
            "value": "Map:‚Äá100%"
          }
        },
        "09308b26c35a471ab9133066d2632a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25fbdbaf784642818ddbe5a81c8728ce",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49bc3f0266f143c5a963c45c4dc58cbf",
            "value": 500
          }
        },
        "a8f8ef9154b24b6580b70a807410f615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_570bab1fd0524f4096a8296bf43f775a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c6ab76102f2a493b902bcb8507efd09d",
            "value": "‚Äá500/500‚Äá[00:01&lt;00:00,‚Äá377.37‚Äáexamples/s]"
          }
        },
        "2182a4bc7c8d4746b7589d95127356fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25dc60de85cc4df99aaaf2ad06e39363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a6c694c7ba49bc836f9ed04da242b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25fbdbaf784642818ddbe5a81c8728ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49bc3f0266f143c5a963c45c4dc58cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "570bab1fd0524f4096a8296bf43f775a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6ab76102f2a493b902bcb8507efd09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693,
          "referenced_widgets": [
            "adac8f745c7c4682941a95ff88b2f961",
            "23bee10ef4af48629ab1cbe6f9b28c9a",
            "09308b26c35a471ab9133066d2632a91",
            "a8f8ef9154b24b6580b70a807410f615",
            "2182a4bc7c8d4746b7589d95127356fb",
            "25dc60de85cc4df99aaaf2ad06e39363",
            "e0a6c694c7ba49bc836f9ed04da242b8",
            "25fbdbaf784642818ddbe5a81c8728ce",
            "49bc3f0266f143c5a963c45c4dc58cbf",
            "570bab1fd0524f4096a8296bf43f775a",
            "c6ab76102f2a493b902bcb8507efd09d"
          ]
        },
        "id": "bzPaMt7295-Z",
        "outputId": "0409e08a-f6e1-482c-c601-a51c5972a245"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Loading CNN/DailyMail dataset...\n",
            "üßπ Preprocessing datasets...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adac8f745c7c4682941a95ff88b2f961"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-2901136837.py:80: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting fine-tuning...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 02:50, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.881554</td>\n",
              "      <td>1.560000</td>\n",
              "      <td>0.780000</td>\n",
              "      <td>1.350000</td>\n",
              "      <td>1.340000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.715500</td>\n",
              "      <td>0.857412</td>\n",
              "      <td>7.210000</td>\n",
              "      <td>3.080000</td>\n",
              "      <td>6.110000</td>\n",
              "      <td>6.060000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model fine-tuned and saved to './t5-cnn-finetuned'\n",
            "üîÅ Loading fine-tuned model for inference...\n",
            "\n",
            "============================================================\n",
            "üí¨ INTERACTIVE SUMMARIZATION MODE\n",
            "Paste any article below. Type 'quit' to exit.\n",
            "============================================================\n",
            "\n",
            "üìù Enter your article (or 'quit' to exit):\n",
            "> It‚Äôs not possible to make a single Python function like that 100% accurate at converting C++ code into Python, because:  C++ and Python are fundamentally different languages (syntax, typing, memory model, OOP semantics, templates, etc.).  There‚Äôs no direct one-to-one mapping for many constructs (like pointers, references, templates, manual memory management, STL containers, etc.).  A ‚Äúperfect‚Äù translation would require a full compiler front-end for C++ that parses its AST (Abstract Syntax Tree) and converts it to an equivalent Python AST ‚Äî not simple string replacements.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç ORIGINAL TEXT (first 500 chars):\n",
            "It‚Äôs not possible to make a single Python function like that 100% accurate at converting C++ code into Python, because:  C++ and Python are fundamentally different languages (syntax, typing, memory model, OOP semantics, templates, etc.).  There‚Äôs no direct one-to-one mapping for many constructs (like pointers, references, templates, manual memory management, STL containers, etc.).  A ‚Äúperfect‚Äù translation would require a full compiler front-end for C++ that parses its AST (Abstract Syntax Tree) ...\n",
            "\n",
            "‚ú® GENERATED SUMMARY:\n",
            "C++ and Python are fundamentally different languages . There‚Äôs no direct one-to-one mapping for many constructs . A ‚Äúperfect‚Äù translation would require a full compiler front-end for C++ .\n",
            "\n",
            "üìù Enter your article (or 'quit' to exit):\n",
            "> quit\n",
            "üëã Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# summarization_assignment.py\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        ")\n",
        "from transformers import pipeline\n",
        "import evaluate\n",
        "\n",
        "# ==============================\n",
        "# 1. Load Dataset\n",
        "# ==============================\n",
        "print(\"üì• Loading CNN/DailyMail dataset...\")\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "\n",
        "# Use smaller subsets for faster training (adjust as needed)\n",
        "train_dataset = dataset[\"train\"].select(range(2000))      # 2K samples for demo\n",
        "eval_dataset = dataset[\"validation\"].select(range(500))   # 500 for eval\n",
        "\n",
        "# ==============================\n",
        "# 2. Model & Tokenizer Setup\n",
        "# ==============================\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    inputs = [\"summarize: \" + doc for doc in examples[\"article\"]]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(examples[\"highlights\"], max_length=128, truncation=True, padding=\"max_length\")\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "print(\"üßπ Preprocessing datasets...\")\n",
        "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_eval = eval_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# ==============================\n",
        "# 3. ROUGE Metric\n",
        "# ==============================\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    return {k: round(v * 100, 2) for k, v in result.items()}\n",
        "\n",
        "# ==============================\n",
        "# 4. Training Setup\n",
        "# ==============================\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./t5-cnn-finetuned\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=2,\n",
        "    predict_with_generate=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",  # disable W&B etc.\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 5. Fine-tune the Model\n",
        "# ==============================\n",
        "print(\"üöÄ Starting fine-tuning...\")\n",
        "trainer.train()\n",
        "\n",
        "# Save final model\n",
        "trainer.save_model(\"./t5-cnn-finetuned\")\n",
        "tokenizer.save_pretrained(\"./t5-cnn-finetuned\")\n",
        "\n",
        "print(\"‚úÖ Model fine-tuned and saved to './t5-cnn-finetuned'\")\n",
        "\n",
        "# ==============================\n",
        "# 6. Load Fine-tuned Model for Inference\n",
        "# ==============================\n",
        "print(\"üîÅ Loading fine-tuned model for inference...\")\n",
        "summarizer = pipeline(\n",
        "    \"summarization\",\n",
        "    model=\"./t5-cnn-finetuned\",\n",
        "    tokenizer=\"./t5-cnn-finetuned\",\n",
        "    device=0 if torch.cuda.is_available() else -1,\n",
        "    framework=\"pt\"\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 7. Infinite Interactive Loop\n",
        "# ==============================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üí¨ INTERACTIVE SUMMARIZATION MODE\")\n",
        "print(\"Paste any article below. Type 'quit' to exit.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "while True:\n",
        "    print(\"\\nüìù Enter your article (or 'quit' to exit):\")\n",
        "    user_input = input(\"> \").strip()\n",
        "\n",
        "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "        print(\"üëã Goodbye!\")\n",
        "        break\n",
        "\n",
        "    if not user_input:\n",
        "        print(\"‚ö†Ô∏è Please enter non-empty text.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Generate summary\n",
        "        result = summarizer(\n",
        "            user_input,\n",
        "            max_length=120,\n",
        "            min_length=30,\n",
        "            do_sample=False,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        summary = result[0][\"summary_text\"]\n",
        "\n",
        "        print(\"\\nüîç ORIGINAL TEXT (first 500 chars):\")\n",
        "        print(user_input[:500] + \"...\" if len(user_input) > 500 else user_input)\n",
        "        print(\"\\n‚ú® GENERATED SUMMARY:\")\n",
        "        print(summary)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during summarization: {e}\")"
      ]
    }
  ]
}